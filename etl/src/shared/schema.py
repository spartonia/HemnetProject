from pyspark.sql.types import *


canonical_schema = (StructType()
   .add("id", IntegerType(), True)
   .add("broker_firm", StringType(), True)
   .add("broker_agency_id", IntegerType(), True)
   .add("location", StringType(), True)
   .add("locations", StructType()
      .add("country", StringType(), True)
      .add("county", StringType(), True)
      .add("municipality", StringType(), True)
      .add("postal_city", StringType(), True)
      .add("street", StringType(), True)
      .add("city", StringType(), True)
      .add("district", StringType(), True))
   .add("offers_selling_price", BooleanType(), True)
   .add("status", StringType(), True)
   .add("housing_form", StringType(), True)
   .add("street_address", StringType(), True)
   .add("borattavgift", IntegerType(), True)
   .add("upcoming_open_houses", BooleanType(), True)
   .add("long_description", BooleanType(), True)
   .add("has_floorplan", BooleanType(), True)
   .add("amenities", ArrayType(StringType(), True))
)
